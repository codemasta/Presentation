{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "from math import log, sqrt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "mails = pd.read_csv('spam.csv', encoding = 'latin-1')\n",
    "mails.drop(['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'], axis = 1, inplace = True)\n",
    "mails.rename(columns = {'v1': 'labels', 'v2': 'message'}, inplace = True)\n",
    "mails['label'] = mails['labels'].map({'ham': 0, 'spam': 1})\n",
    "mails.drop(['labels'], axis = 1, inplace = True)\n",
    "\n",
    "trainIndex = list()\n",
    "for i in range(mails.shape[0]):\n",
    "    trainIndex += [i]\n",
    "\n",
    "trainData = mails.loc[trainIndex]\n",
    "\n",
    "spam_words = ' '.join(list(mails[mails['label'] == 1]['message']))\n",
    "spam_wc = WordCloud(width = 512,height = 512).generate(spam_words)\n",
    "plt.figure(figsize = (6,6), facecolor = 'k')\n",
    "plt.imshow(spam_wc)\n",
    "plt.axis('off')\n",
    "plt.tight_layout(pad = 0)\n",
    "plt.show()\n",
    "\n",
    "ham_words = ' '.join(list(mails[mails['label'] == 0]['message']))\n",
    "ham_wc = WordCloud(width = 512,height = 512).generate(ham_words)\n",
    "plt.figure(figsize = (6,6), facecolor = 'k')\n",
    "plt.imshow(ham_wc)\n",
    "plt.axis('off')\n",
    "plt.tight_layout(pad = 0)\n",
    "plt.show()\n",
    "\n",
    "#Preprocess message\n",
    "def process_message(message, lower_case = True, stem = True, stop_words = True, gram = 2):\n",
    "    if lower_case:\n",
    "        message = message.lower()\n",
    "    words = word_tokenize(message)\n",
    "    words = [w for w in words if len(w) > 2]\n",
    "    if gram > 0:\n",
    "        w = []\n",
    "        for i in range(len(words) - gram + 1):\n",
    "            w += [' '.join(words[i:i + gram])]\n",
    "        return w\n",
    "    if stop_words:\n",
    "        sw = stopwords.words('english')\n",
    "        words = [word for word in words if word not in sw]\n",
    "    if stem:\n",
    "        stemmer = PorterStemmer()\n",
    "        words = [stemmer.stem(word) for word in words]  \n",
    "    return words\n",
    "\n",
    "class SpamClassifier(object):\n",
    "    def __init__(self, trainData, method = 'tf-idf'):\n",
    "        self.mails, self.labels = trainData['message'], trainData['label']#load traindata\n",
    "        self.method = method\n",
    "\n",
    "    def train(self):\n",
    "        self.calc_TF_and_IDF()\n",
    "        if self.method == 'tf-idf':\n",
    "            self.calc_TF_IDF()\n",
    "\n",
    "    \n",
    "\n",
    "    def calc_TF_and_IDF(self):\n",
    "        noOfMessages = self.mails.shape[0]\n",
    "        \n",
    "        #identify spam and ham from traindata\n",
    "        self.spam_mails, self.ham_mails = self.labels.value_counts()[1], self.labels.value_counts()[0]\n",
    "        \n",
    "        #Initialize\n",
    "        self.total_mails = self.spam_mails + self.ham_mails\n",
    "        self.tf_spam = dict()\n",
    "        self.tf_ham = dict()\n",
    "        self.idf_spam = dict()\n",
    "        self.idf_ham = dict()\n",
    "        \n",
    "        for i in range(noOfMessages):\n",
    "            message_processed = process_message(self.mails[i]) #tokenize, remove stopwords and stemming the traindata\n",
    "            \n",
    "            count = list() #To keep track of whether the word has ocured in the message or not.\n",
    "                           #For IDF(Inverse Document Frequency)\n",
    "            for word in message_processed:#check each word of single traindata email for 1 or 0\n",
    "                if self.labels[i]:\n",
    "                    self.tf_spam[word] = self.tf_spam.get(word, 0) + 1 #count of Spam words\n",
    "                else:\n",
    "                    self.tf_ham[word] = self.tf_ham.get(word, 0) + 1 #count of Ham words \n",
    "                if word not in count:\n",
    "                    count += [word]\n",
    "            for word in count:\n",
    "                if self.labels[i]:\n",
    "                    self.idf_spam[word] = self.idf_spam.get(word, 0) + 1\n",
    "                else:\n",
    "                    self.idf_ham[word] = self.idf_ham.get(word, 0) + 1\n",
    "\n",
    "    def calc_TF_IDF(self):\n",
    "        self.prob_spam = dict()\n",
    "        self.prob_ham = dict()\n",
    "        self.sum_tf_idf_spam = 0\n",
    "        self.sum_tf_idf_ham = 0\n",
    "        \n",
    "        #Calculate probability of spam words using tf-idf\n",
    "        for word in self.tf_spam:\n",
    "            self.prob_spam[word] = (self.tf_spam[word]) * log((self.spam_mails + self.ham_mails) \\\n",
    "                                                          / (self.idf_spam[word] + self.idf_ham.get(word, 0)))\n",
    "            self.sum_tf_idf_spam += self.prob_spam[word]        \n",
    "        for word in self.tf_spam:            \n",
    "            self.prob_spam[word] = (self.prob_spam[word] + 1) / (self.sum_tf_idf_spam + len(list(self.prob_spam.keys())))\n",
    "            \n",
    "        #Calculate probability of Ham words using tf-idf    \n",
    "        for word in self.tf_ham:\n",
    "            self.prob_ham[word] = (self.tf_ham[word]) * log((self.spam_mails + self.ham_mails) \\\n",
    "                                                          / (self.idf_spam.get(word, 0) + self.idf_ham[word]))\n",
    "            self.sum_tf_idf_ham += self.prob_ham[word]            \n",
    "        for word in self.tf_ham:\n",
    "            self.prob_ham[word] = (self.prob_ham[word] + 1) / (self.sum_tf_idf_ham + len(list(self.prob_ham.keys())))\n",
    "            \n",
    "        self.prob_spam_mail, self.prob_ham_mail = self.spam_mails / self.total_mails, self.ham_mails / self.total_mails         \n",
    "\n",
    "    def classify(self, processed_message):\n",
    "        pSpam, pHam = 0, 0\n",
    "        \n",
    "        for word in processed_message:                \n",
    "            if word in self.prob_spam: # check prob for each ham and spam word and detect spam if pSpam >= pHam\n",
    "                pSpam += log(self.prob_spam[word])\n",
    "            else:\n",
    "                if self.method == 'tf-idf':\n",
    "                    pSpam -= log(self.sum_tf_idf_spam + len(list(self.prob_spam.keys()))) #remove IDF from pSpam\n",
    "            if word in self.prob_ham:\n",
    "                pHam += log(self.prob_ham[word])\n",
    "            else:\n",
    "                if self.method == 'tf-idf':\n",
    "                    pHam -= log(self.sum_tf_idf_ham + len(list(self.prob_ham.keys()))) #remove IDF from pHam\n",
    "            pSpam += log(self.prob_spam_mail)\n",
    "            pHam += log(self.prob_ham_mail)\n",
    "        return pSpam >= pHam\n",
    "    \n",
    "sc_tf_idf = SpamClassifier(trainData, 'tf-idf')\n",
    "sc_tf_idf.train()\n",
    "\n",
    "message='hello my name is Adeyinka Oluwaseun'\n",
    "pm=process_message(message)\n",
    "if(sc_tf_idf.classify(pm)):\n",
    "    print(\"Input text: \" + message)\n",
    "    print(\"Spam Detected\")\n",
    "else:\n",
    "    print(\"Input text: \" + message)\n",
    "    print(\"No Spam Detected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\programdata\\anaconda3\\lib\\site-packages (3.4.5)\n",
      "Requirement already satisfied: six in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk) (1.12.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
